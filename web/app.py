
import streamlit as st
import os
import torch
from model import RandomFrameClassifier
from utils import extract_audio_tensor, extract_video_tensor_cv2
import tempfile
import yt_dlp
import traceback
from pathlib import Path

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

@st.cache_resource
def load_model(checkpoint_path="checkpoint_epoch_5.pth"):
    st.write("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    model = RandomFrameClassifier(num_classes=4)
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model.to(device)
    model.eval()
    st.success("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    return model

model = load_model()

st.title("üé¨ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∏—Ä–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–π–ª–µ—Ä–∞ –ø–æ —Å—Å—ã–ª–∫–µ YouTube")

url = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ (YouTube):")

if url:
    with st.spinner("‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–µ–º –≤–∏–¥–µ–æ..."):
        tempdir = tempfile.TemporaryDirectory()
        output_template = os.path.join(tempdir.name, "video.%(ext)s")

        ydl_opts = {
            'format': 'bestvideo+bestaudio/best',
            'outtmpl': output_template,
            'merge_output_format': 'mp4',
            'quiet': True,
            'noplaylist': True
        }

        try:
            st.write("üîó –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–∞—á–∞–ª–æ—Å—å...")
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                result = ydl.download([url])

            # –ò—â–µ–º –ø–æ–ª—É—á–∏–≤—à–∏–π—Å—è —Ñ–∞–π–ª
            downloaded_files = list(Path(tempdir.name).glob("video.*"))
            if not downloaded_files:
                st.error("‚ùå –í–∏–¥–µ–æ –Ω–µ –±—ã–ª–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ.")
                st.stop()

            final_video_path = str(downloaded_files[0])

            if os.path.getsize(final_video_path) < 100_000:
                st.error("‚ùå –í–∏–¥–µ–æ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–æ.")
                st.stop()

            st.success("‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ!")
            st.video(final_video_path)

            with st.spinner("üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º..."):
                st.write("üñºÔ∏è –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤...")
                video_tensor = extract_video_tensor_cv2(final_video_path).to(device)

                st.write("üîä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ...")
                audio_tensor = extract_audio_tensor(final_video_path).to(device)

                st.write("ü§ñ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ...")
                with torch.no_grad():
                    output = model(video_tensor, audio_tensor)
                    predicted_class = torch.argmax(output, dim=1).item() + 1

                st.success(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –≤–∏—Ä–∞–ª—å–Ω–æ—Å—Ç–∏: **{predicted_class}** (–æ—Ç 1 –¥–æ 4)")
        except Exception as e:
            st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ:")
            st.code(traceback.format_exc())
        finally:
            tempdir.cleanup()
